{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f721a71a",
   "metadata": {},
   "source": [
    "## Aprendizagem Autom√°tica 2023/2024\n",
    "\n",
    "### 3rd Home assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdea849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, max_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "366998af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_reg_statistics(y_test, preds):\n",
    "    print(\"The RVE is: \", explained_variance_score(y_test, preds))\n",
    "    print(\"The rmse is: \", mean_squared_error(y_test, preds, squared=False))\n",
    "    corr, pval=pearsonr(y_test, preds)\n",
    "    print(\"The Correlation Score is is: %6.4f (p-value=%e)\\n\"%(corr,pval))\n",
    "    print(\"The Maximum Error is is: \", max_error(y_test, preds))\n",
    "    print(\"The Mean Absolute Error is: \", mean_absolute_error(y_test, preds))\n",
    "    #plt.figure(figsize=(5,5))\n",
    "    #plt.scatter(preds, y_test)\n",
    "    #plt.plot((50, 350), (50, 350), c=\"r\")\n",
    "    #plt.grid()\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f0333",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe3e6497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D00</th>\n",
       "      <th>D01</th>\n",
       "      <th>D02</th>\n",
       "      <th>D03</th>\n",
       "      <th>D04</th>\n",
       "      <th>D05</th>\n",
       "      <th>D06</th>\n",
       "      <th>D07</th>\n",
       "      <th>D08</th>\n",
       "      <th>D09</th>\n",
       "      <th>...</th>\n",
       "      <th>FP2079</th>\n",
       "      <th>FP2080</th>\n",
       "      <th>FP2081</th>\n",
       "      <th>FP2082</th>\n",
       "      <th>FP2083</th>\n",
       "      <th>FP2084</th>\n",
       "      <th>FP2085</th>\n",
       "      <th>FP2086</th>\n",
       "      <th>FP2087</th>\n",
       "      <th>FP2088</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>541.280138</td>\n",
       "      <td>541.656</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>426.197714</td>\n",
       "      <td>426.582</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348.183778</td>\n",
       "      <td>348.446</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1455.763803</td>\n",
       "      <td>1456.831</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>387.151368</td>\n",
       "      <td>387.886</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7332</th>\n",
       "      <td>467.149047</td>\n",
       "      <td>467.513</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7333</th>\n",
       "      <td>240.162649</td>\n",
       "      <td>240.350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7334</th>\n",
       "      <td>510.317874</td>\n",
       "      <td>510.802</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7335</th>\n",
       "      <td>393.187483</td>\n",
       "      <td>393.556</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7336</th>\n",
       "      <td>484.056123</td>\n",
       "      <td>485.462</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7337 rows √ó 2132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              D00       D01   D02   D03   D04   D05   D06    D07    D08   D09  \\\n",
       "0      541.280138   541.656  10.0   1.0   8.0   1.0  10.0   40.0   75.0  10.0   \n",
       "1      426.197714   426.582   5.0   1.0   9.0   1.0   4.0   30.0   60.0   6.0   \n",
       "2      348.183778   348.446   4.0   0.0   3.0   0.0   3.0   26.0   50.0   4.0   \n",
       "3     1455.763803  1456.831  27.0  19.0  23.0  17.0  16.0  105.0  206.0  28.0   \n",
       "4      387.151368   387.886   4.0   0.0   4.0   0.0   4.0   27.0   50.0   6.0   \n",
       "...           ...       ...   ...   ...   ...   ...   ...    ...    ...   ...   \n",
       "7332   467.149047   467.513   6.0   0.0   6.0   0.0   5.0   32.0   56.0  10.0   \n",
       "7333   240.162649   240.350   2.0   0.0   3.0   0.0   2.0   18.0   38.0   2.0   \n",
       "7334   510.317874   510.802   4.0   0.0  10.0   0.0   4.0   37.0   79.0   5.0   \n",
       "7335   393.187483   393.556   4.0   2.0   5.0   1.0   5.0   28.0   55.0   5.0   \n",
       "7336   484.056123   485.462   6.0   1.0   7.0   1.0   6.0   30.0   52.0  10.0   \n",
       "\n",
       "      ...  FP2079  FP2080  FP2081  FP2082  FP2083  FP2084  FP2085  FP2086  \\\n",
       "0     ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     ...     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "4     ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "7332  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7333  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7334  ...     0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "7335  ...     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7336  ...     0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      FP2087  FP2088  \n",
       "0        0.0     0.0  \n",
       "1        0.0     0.0  \n",
       "2        0.0     0.0  \n",
       "3        1.0     1.0  \n",
       "4        0.0     0.0  \n",
       "...      ...     ...  \n",
       "7332     0.0     0.0  \n",
       "7333     1.0     0.0  \n",
       "7334     0.0     0.0  \n",
       "7335     0.0     0.0  \n",
       "7336     0.0     0.0  \n",
       "\n",
       "[7337 rows x 2132 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_ivs, y_train, col_names = pickle.load(open(\"drd2_data.pickle\", \"rb\"))\n",
    "\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train, columns=col_names)#convert the arrays to pandas dataframes\n",
    "X_ivs_df = pd.DataFrame(X_ivs, columns=col_names)\n",
    "\n",
    "\n",
    "X_train_df\n",
    "#how much the molecule inhibts the receptor=y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b817f",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe4c1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the data\n",
    "scaler = StandardScaler()\n",
    "Xs_train = pd.DataFrame(scaler.fit_transform(X_train_df), columns=X_train_df.columns)\n",
    "Xs_ivs = pd.DataFrame(scaler.transform(X_ivs_df), columns=X_ivs_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d507a05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Checking for missing values \n",
    "check_nan = Xs_train.isnull().values.any()\n",
    "print(check_nan)\n",
    "\n",
    "check_nan = Xs_ivs.isnull().values.any()\n",
    "print(check_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f15b362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the dataset in training and testing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99207a36",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6880d",
   "metadata": {},
   "source": [
    "### Random Forest for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e963b565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2123</th>\n",
       "      <th>2124</th>\n",
       "      <th>2125</th>\n",
       "      <th>2126</th>\n",
       "      <th>2127</th>\n",
       "      <th>2128</th>\n",
       "      <th>2129</th>\n",
       "      <th>2130</th>\n",
       "      <th>2131</th>\n",
       "      <th>2132</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130290</td>\n",
       "      <td>0.129406</td>\n",
       "      <td>0.858046</td>\n",
       "      <td>-0.081854</td>\n",
       "      <td>-0.088142</td>\n",
       "      <td>-0.058057</td>\n",
       "      <td>1.549653</td>\n",
       "      <td>0.116628</td>\n",
       "      <td>-0.045254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.491862</td>\n",
       "      <td>-0.492954</td>\n",
       "      <td>-1.064899</td>\n",
       "      <td>-0.477479</td>\n",
       "      <td>-0.589590</td>\n",
       "      <td>-0.508809</td>\n",
       "      <td>-1.318794</td>\n",
       "      <td>-0.426772</td>\n",
       "      <td>-0.355960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>5.928141</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.602119</td>\n",
       "      <td>-0.603136</td>\n",
       "      <td>-0.584163</td>\n",
       "      <td>-0.081854</td>\n",
       "      <td>-0.589590</td>\n",
       "      <td>-0.058057</td>\n",
       "      <td>-0.601682</td>\n",
       "      <td>-0.504401</td>\n",
       "      <td>-0.472474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>5.029661</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.198970</td>\n",
       "      <td>-0.106337</td>\n",
       "      <td>-0.107602</td>\n",
       "      <td>0.377310</td>\n",
       "      <td>-0.477479</td>\n",
       "      <td>0.246156</td>\n",
       "      <td>-0.508809</td>\n",
       "      <td>0.832542</td>\n",
       "      <td>-0.038629</td>\n",
       "      <td>-0.122930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>7.331694</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.507495</td>\n",
       "      <td>-0.079080</td>\n",
       "      <td>-0.079887</td>\n",
       "      <td>-0.103427</td>\n",
       "      <td>-0.477479</td>\n",
       "      <td>0.079007</td>\n",
       "      <td>-0.508809</td>\n",
       "      <td>0.115430</td>\n",
       "      <td>-0.116258</td>\n",
       "      <td>-0.200607</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>0.089334</td>\n",
       "      <td>-0.112316</td>\n",
       "      <td>-0.113142</td>\n",
       "      <td>0.136941</td>\n",
       "      <td>-0.081854</td>\n",
       "      <td>-0.589590</td>\n",
       "      <td>-0.058057</td>\n",
       "      <td>0.473986</td>\n",
       "      <td>-0.116258</td>\n",
       "      <td>-0.433636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>0.491644</td>\n",
       "      <td>0.278713</td>\n",
       "      <td>0.282670</td>\n",
       "      <td>-0.103427</td>\n",
       "      <td>-0.081854</td>\n",
       "      <td>-0.255292</td>\n",
       "      <td>-0.058057</td>\n",
       "      <td>-0.243126</td>\n",
       "      <td>0.194257</td>\n",
       "      <td>-0.045254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>5.116060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>0.537492</td>\n",
       "      <td>-0.613018</td>\n",
       "      <td>-0.613986</td>\n",
       "      <td>-0.824531</td>\n",
       "      <td>-0.477479</td>\n",
       "      <td>-0.589590</td>\n",
       "      <td>-0.508809</td>\n",
       "      <td>-0.960238</td>\n",
       "      <td>-0.504401</td>\n",
       "      <td>-0.394798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>0.104399</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>-0.103427</td>\n",
       "      <td>-0.477479</td>\n",
       "      <td>-0.255292</td>\n",
       "      <td>-0.508809</td>\n",
       "      <td>-0.243126</td>\n",
       "      <td>0.038999</td>\n",
       "      <td>-0.084092</td>\n",
       "      <td>...</td>\n",
       "      <td>1.234467</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5868</th>\n",
       "      <td>0.046272</td>\n",
       "      <td>0.764300</td>\n",
       "      <td>0.763243</td>\n",
       "      <td>0.136941</td>\n",
       "      <td>-0.477479</td>\n",
       "      <td>1.081903</td>\n",
       "      <td>-0.508809</td>\n",
       "      <td>0.473986</td>\n",
       "      <td>0.970543</td>\n",
       "      <td>0.886863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>3.210153</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5869 rows √ó 2133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.000000  0.130290  0.129406  0.858046 -0.081854 -0.088142 -0.058057   \n",
       "1     0.250000 -0.491862 -0.492954 -1.064899 -0.477479 -0.589590 -0.508809   \n",
       "2     0.000000 -0.602119 -0.603136 -0.584163 -0.081854 -0.589590 -0.058057   \n",
       "3     0.198970 -0.106337 -0.107602  0.377310 -0.477479  0.246156 -0.508809   \n",
       "4     0.507495 -0.079080 -0.079887 -0.103427 -0.477479  0.079007 -0.508809   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5864  0.089334 -0.112316 -0.113142  0.136941 -0.081854 -0.589590 -0.058057   \n",
       "5865  0.491644  0.278713  0.282670 -0.103427 -0.081854 -0.255292 -0.058057   \n",
       "5866  0.537492 -0.613018 -0.613986 -0.824531 -0.477479 -0.589590 -0.508809   \n",
       "5867  0.104399  0.014756  0.013408 -0.103427 -0.477479 -0.255292 -0.508809   \n",
       "5868  0.046272  0.764300  0.763243  0.136941 -0.477479  1.081903 -0.508809   \n",
       "\n",
       "          7         8         9     ...      2123      2124      2125  \\\n",
       "0     1.549653  0.116628 -0.045254  ... -0.810066 -0.195463 -0.179087   \n",
       "1    -1.318794 -0.426772 -0.355960  ... -0.810066 -0.195463 -0.179087   \n",
       "2    -0.601682 -0.504401 -0.472474  ... -0.810066 -0.195463 -0.179087   \n",
       "3     0.832542 -0.038629 -0.122930  ... -0.810066 -0.195463 -0.179087   \n",
       "4     0.115430 -0.116258 -0.200607  ... -0.810066 -0.195463 -0.179087   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5864  0.473986 -0.116258 -0.433636  ... -0.810066 -0.195463 -0.179087   \n",
       "5865 -0.243126  0.194257 -0.045254  ... -0.810066 -0.195463 -0.179087   \n",
       "5866 -0.960238 -0.504401 -0.394798  ... -0.810066 -0.195463 -0.179087   \n",
       "5867 -0.243126  0.038999 -0.084092  ...  1.234467 -0.195463 -0.179087   \n",
       "5868  0.473986  0.970543  0.886863  ... -0.810066 -0.195463 -0.179087   \n",
       "\n",
       "          2126      2127      2128      2129      2130      2131      2132  \n",
       "0    -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "1    -0.311512  5.928141 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "2    -0.311512 -0.168687 -0.105656 -0.136394  5.029661 -0.323477 -0.195463  \n",
       "3    -0.311512 -0.168687 -0.105656  7.331694 -0.198821 -0.323477 -0.195463  \n",
       "4    -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5864 -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "5865 -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477  5.116060  \n",
       "5866 -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "5867 -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "5868  3.210153 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "\n",
       "[5869 rows x 2133 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N,M=X_train.shape\n",
    "N,M\n",
    "v=np.hstack((y_train.reshape((N,1)), X_train))\n",
    "pd.DataFrame(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4832337c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importances:  [3.90440067e-03 3.89625059e-03 2.62879089e-03 ... 8.90369571e-05\n",
      " 3.95498492e-04 1.51153768e-04]\n",
      "Default threshold:  0.00046904315196998124\n",
      "The features selected are columns:  [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   22   23   24   25   26   27   28   29\n",
      "   30   31   32   33   34   35   36   37   38   39   40   41   42   50\n",
      "   62   67   74   76   83   96   99  103  106  112  122  152  154  157\n",
      "  165  172  175  180  186  198  199  200  214  216  229  232  234  243\n",
      "  246  278  287  292  303  316  326  335  336  340  347  348  351  353\n",
      "  357  362  364  370  371  377  381  386  390  396  421  440  442  444\n",
      "  451  455  459  472  494  502  513  525  536  538  546  551  558  559\n",
      "  561  565  566  569  570  572  608  615  617  623  630  640  646  675\n",
      "  676  679  687  695  699  711  717  719  722  727  728  747  765  769\n",
      "  770  778  790  808  811  815  819  824  839  851  853  867  871  873\n",
      "  876  879  886  889  891  909  916  917  924  939  945  950  956  959\n",
      "  965  966  973  981  982  994 1013 1020 1023 1027 1029 1033 1037 1041\n",
      " 1053 1054 1063 1073 1075 1086 1087 1088 1090 1106 1121 1135 1139 1147\n",
      " 1161 1166 1167 1168 1171 1176 1191 1201 1212 1214 1219 1245 1247 1248\n",
      " 1260 1266 1279 1283 1284 1285 1286 1303 1318 1319 1320 1329 1333 1338\n",
      " 1351 1354 1360 1366 1377 1383 1395 1397 1405 1418 1429 1433 1440 1445\n",
      " 1453 1454 1481 1483 1496 1499 1507 1510 1520 1526 1527 1528 1538 1540\n",
      " 1556 1565 1575 1589 1598 1604 1605 1641 1649 1651 1652 1658 1665 1667\n",
      " 1684 1685 1686 1687 1706 1708 1709 1716 1722 1736 1752 1754 1766 1775\n",
      " 1777 1778 1779 1781 1782 1783 1787 1789 1793 1810 1811 1815 1821 1839\n",
      " 1841 1850 1857 1866 1868 1872 1883 1892 1893 1897 1912 1916 1917 1918\n",
      " 1921 1922 1925 1931 1934 1946 1962 1963 1968 1973 1978 1980 1983 1985\n",
      " 1992 1998 2004 2017 2019 2025 2028 2029 2050 2062 2069 2076 2078 2079\n",
      " 2080 2088 2095 2098 2108 2118 2122]\n"
     ]
    }
   ],
   "source": [
    "rfr=RandomForestRegressor(random_state=0)\n",
    "sel = SelectFromModel(estimator=rfr, threshold='mean') #Change the threshold! See what happens!\n",
    "sel.fit(X_train, y_train)\n",
    "\n",
    "print(\"Importances: \", sel.estimator_.feature_importances_)\n",
    "\n",
    "print(\"Default threshold: \", sel.threshold_)\n",
    "\n",
    "features=sel.get_support()\n",
    "Features_selected =np.arange(M)[features]\n",
    "print(\"The features selected are columns: \", Features_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "174c32c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nX_train=sel.transform(X_train)\n",
    "nX_test=sel.transform(X_test)\n",
    "nX_ivs=sel.transform(Xs_ivs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bac71a",
   "metadata": {},
   "source": [
    "### KNN, SVM, DT, Ridge Regression, Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9137a8cc",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "957f124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_mse = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "gammas = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "Cs = [1, 10, 100, 1e3, 1e4, 1e5]\n",
    "\n",
    "for gamma in gammas:\n",
    "    for C in Cs:\n",
    "        svr = SVR(gamma=gamma, C=C)\n",
    "        svr.fit(nX_train, y_train)\n",
    "        preds = svr.predict(nX_test)\n",
    "        mse = mean_squared_error(y_test, preds)\n",
    "        \n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_params = {'gamma': gamma, 'C': C}\n",
    "\n",
    "best_svr = SVR(**best_params)\n",
    "best_svr.fit(nX_train, y_train)\n",
    "preds = best_svr.predict(nX_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5813c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=10, gamma=0.001)\n",
      "The RVE is:  0.6269828205917798\n",
      "The rmse is:  0.1683107548449815\n",
      "The Correlation Score is is: 0.7919 (p-value=2.128546e-316)\n",
      "\n",
      "The Maximum Error is is:  0.7813564151906202\n",
      "The Mean Absolute Error is:  0.1269837317599825\n"
     ]
    }
   ],
   "source": [
    "print(best_svr)\n",
    "present_reg_statistics(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a1fe4",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed9a67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mse = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "# Define the range of hyperparameters to search\n",
    "max_depths = [15, 20, 25, 30]  # Example depth values to search\n",
    "min_samples_leafs = [15, 20, 25, 30]  # Example min samples leaf values\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    for min_samples_leaf in min_samples_leafs:\n",
    "        # Create and train the model with different hyperparameters\n",
    "        dt = DecisionTreeRegressor(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "        dt.fit(nX_train, y_train)\n",
    "        preds = dt.predict(nX_test)\n",
    "        mse = mean_squared_error(y_test, preds)\n",
    "        \n",
    "        # Update best parameters if this combination performs better\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_params = {'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "# Train the model using the best hyperparameters\n",
    "best_dt = DecisionTreeRegressor(**best_params)\n",
    "best_dt.fit(nX_train, y_train)\n",
    "preds = best_dt.predict(nX_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf795945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(max_depth=20, min_samples_leaf=15)\n",
      "The RVE is:  0.40432994343713136\n",
      "The rmse is:  0.2125402551096508\n",
      "The Correlation Score is is: 0.6494 (p-value=1.513982e-176)\n",
      "\n",
      "The Maximum Error is is:  0.8653546494666666\n",
      "The Mean Absolute Error is:  0.16235852877975518\n"
     ]
    }
   ],
   "source": [
    "print(best_dt)\n",
    "present_reg_statistics(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306d334",
   "metadata": {},
   "source": [
    "### Ensemble Models: Bagging-> KNN, DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0ea39",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22e62daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.5730981168258943\n",
      "The rmse is:  0.1799525250480272\n",
      "The Correlation Score is is: 0.7571 (p-value=2.798392e-273)\n",
      "\n",
      "The Maximum Error is is:  0.9230639854\n",
      "The Mean Absolute Error is:  0.13400811925239725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "best_score_bagging_dt = float('inf')\n",
    "best_params_bagging_dt = {}\n",
    "\n",
    "depths = [15, 20, 25]\n",
    "\n",
    "for depth in depths:\n",
    "    dt = DecisionTreeRegressor(max_depth=depth)\n",
    "    bagging_dt = BaggingRegressor(base_estimator=dt, n_estimators=10, random_state=0)\n",
    "    scores = cross_val_score(bagging_dt, nX_train, y_train, cv=5, scoring='explained_variance')\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    if mean_score > best_score_bagging_dt:\n",
    "        best_score_bagging_dt = mean_score\n",
    "        best_params_bagging_dt['max_depth'] = depth\n",
    "\n",
    "#Train the model with the hyperparameters\n",
    "dt = DecisionTreeRegressor(**best_params_bagging_dt)\n",
    "bagging_dt = BaggingRegressor(base_estimator=dt, n_estimators=10, random_state=0)  \n",
    "bagging_dt.fit(nX_train, y_train)\n",
    "bagging_dt_preds = bagging_dt.predict(nX_test)\n",
    "\n",
    "Bg_dt = present_reg_statistics (y_test, bagging_dt_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c8628",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41c374cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.6165924916373591\n",
      "The rmse is:  0.17054630684271474\n",
      "The Correlation Score is is: 0.7857 (p-value=3.834948e-308)\n",
      "\n",
      "The Maximum Error is is:  0.88132395182\n",
      "The Mean Absolute Error is:  0.12536290686752044\n"
     ]
    }
   ],
   "source": [
    "best_score_bagging_knn = float('inf')\n",
    "best_params_bagging_knn = {}\n",
    "\n",
    "n_knn = [3,5,7]\n",
    "\n",
    "for n_neighbors in n_knn:\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    bagging_knn = BaggingRegressor(base_estimator=knn, n_estimators=10, random_state=0)\n",
    "    scores = cross_val_score(bagging_knn, nX_train, y_train, cv=5, scoring='explained_variance')\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    if mean_score > best_score_bagging_knn:\n",
    "        best_score_bagging_knn = mean_score\n",
    "        best_params_bagging_knn['n_neighbors'] = n_neighbors\n",
    "\n",
    "\n",
    "knn = KNeighborsRegressor(**best_params_bagging_knn)  \n",
    "bagging_knn = BaggingRegressor(base_estimator=knn, n_estimators=10, random_state=0)\n",
    "bagging_knn.fit(nX_train, y_train)\n",
    "bagging_knn_preds = bagging_knn.predict(nX_test)\n",
    "\n",
    "Bg_knn = present_reg_statistics (y_test, bagging_knn_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6527258",
   "metadata": {},
   "source": [
    "### Adaboost: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7822318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martaaraujo/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass criterion={} as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.19502851169710167\n",
      "The rmse is:  0.24841768534858083\n",
      "The Correlation Score is is: 0.4994 (p-value=1.900603e-93)\n",
      "\n",
      "The Maximum Error is is:  0.7506088518117645\n",
      "The Mean Absolute Error is:  0.20449309039214755\n"
     ]
    }
   ],
   "source": [
    "best_score_adaboost_dt = float('inf')\n",
    "best_params_adaboost_dt = {}\n",
    "\n",
    "ab_depths = [10, 15, 20]\n",
    "\n",
    "for depth in ab_depths:\n",
    "    adaboost_dt = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=depth),\n",
    "                                     n_estimators=50, learning_rate=1.0, random_state=0)\n",
    "    scores = cross_val_score(adaboost_dt, nX_train, y_train, cv=5, scoring='explained_variance')\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    if mean_score > best_score_adaboost_dt:\n",
    "        best_score_adaboost_dt = mean_score\n",
    "        best_params_adaboost_dt['max_depth'] = depth\n",
    "\n",
    "\n",
    "adaboost_dt = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(best_params_adaboost_dt),\n",
    "                                n_estimators=50, learning_rate=1.0, random_state=0)\n",
    "adaboost_dt = AdaBoostRegressor(**best_params_adaboost_dt)\n",
    "adaboost_dt.fit(nX_train, y_train)\n",
    "adaboost_dt_preds = adaboost_dt.predict(nX_test)\n",
    "\n",
    "AB_dt =  present_reg_statistics (y_test, adaboost_dt_preds )\n",
    "AB_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f09219",
   "metadata": {},
   "source": [
    "### Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46a22735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 3, Mean Score: 0.4884680416536519\n",
      "Depth: 5, Mean Score: 0.5825294344259866\n",
      "Depth: 7, Mean Score: 0.6217275762282396\n",
      "The RVE is:  0.6119852984723875\n",
      "The rmse is:  0.17155141516519923\n",
      "The Correlation Score is is: 0.7836 (p-value=2.307629e-305)\n",
      "\n",
      "The Maximum Error is is:  0.8428387061781568\n",
      "The Mean Absolute Error is:  0.12884387293280794\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "best_score_grad_boost = -float('inf')  # Initialize to a very low value\n",
    "best_params_grad_boost = {}\n",
    "\n",
    "for depth in [3, 5, 7]:\n",
    "    grad_boost = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=depth, random_state=0)\n",
    "    scores = cross_val_score(grad_boost, nX_train, y_train, cv=5, scoring='explained_variance')\n",
    "    mean_score = scores.mean()\n",
    "    print(f\"Depth: {depth}, Mean Score: {mean_score}\")  # Print mean scores for debugging\n",
    "    \n",
    "    if mean_score > best_score_grad_boost:\n",
    "        best_score_grad_boost = mean_score\n",
    "        best_params_grad_boost['max_depth'] = depth\n",
    "\n",
    "if 'max_depth' in best_params_grad_boost:  # Check if the key exists before accessing\n",
    "    m_d = best_params_grad_boost['max_depth']\n",
    "    grad_boost = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=m_d, random_state=0)\n",
    "    grad_boost.fit(nX_train, y_train)\n",
    "    grad_boost_preds = grad_boost.predict(nX_test)\n",
    "\n",
    "    GB = present_reg_statistics(y_test, grad_boost_preds)\n",
    "    print(GB)  # Check the output statistics\n",
    "else:\n",
    "    print(\"No best max_depth found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c271e3",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9040d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.6089058039476718\n",
      "The rmse is:  0.17220827530630956\n",
      "The Correlation Score is is: 0.7823 (p-value=1.202609e-303)\n",
      "\n",
      "The Maximum Error is is:  0.8528495877981186\n",
      "The Mean Absolute Error is:  0.1292475587533101\n"
     ]
    }
   ],
   "source": [
    "best_score_xgboost = -float('inf')\n",
    "best_params_xgboost = {}\n",
    "\n",
    "for depth in [3, 5, 7]:\n",
    "    xgboost = xgb.XGBRegressor(n_estimators=100, max_depth=depth, learning_rate=0.1, random_state=0)\n",
    "    scores = cross_val_score(xgboost, nX_train, y_train, cv=5, scoring='explained_variance')\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    if mean_score > best_score_xgboost:\n",
    "        best_score_xgboost = mean_score\n",
    "        best_params_xgboost['max_depth'] = depth\n",
    "\n",
    "xgb_md = best_params_xgboost['max_depth']\n",
    "xgboost = xgb.XGBRegressor(n_estimators=100, max_depth=xgb_md, learning_rate=0.1, random_state=0)\n",
    "xgboost.fit(nX_train, y_train)\n",
    "xgboost_preds = xgboost.predict(nX_test)\n",
    "\n",
    "XGB = present_reg_statistics (y_test, xgboost_preds )\n",
    "XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db057c",
   "metadata": {},
   "source": [
    "### Estimating y_ivs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4febe6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_ivs: [ 3.21618645e-01  5.67140348e-01  3.56575039e-01  3.87816361e-01\n",
      "  1.47783414e-01 -2.32611729e-02  3.88704028e-01  7.86337611e-01\n",
      "  2.88423028e-01  6.72789212e-01  5.36831810e-01  5.00713145e-01\n",
      "  5.58895433e-01  1.26198066e-01  2.47152893e-01  1.98738706e-01\n",
      "  2.10015056e-01  3.31103346e-01  4.02695744e-01  2.59648152e-02\n",
      "  8.91738337e-01  2.54842884e-01  5.26635598e-01  1.94763568e-01\n",
      "  1.85327859e-01  3.53022095e-01  1.65073351e-01  1.82655778e-01\n",
      "  2.05809622e-01  2.22439422e-01 -1.06726186e-02  4.33018900e-01\n",
      "  3.22136869e-01  5.07384644e-01  7.88432011e-01  3.85918002e-01\n",
      "  1.96574107e-01  5.83590390e-01  2.91419852e-01  5.36953006e-01\n",
      "  2.14407813e-01 -1.82242903e-02  2.07291192e-01  4.42951752e-01\n",
      "  3.07263130e-01  4.22397557e-01  7.97837974e-01 -9.90442577e-02\n",
      "  3.91384406e-01  3.54191403e-01  3.00872337e-01  1.25103436e-01\n",
      "  4.62608968e-02  1.98279345e-01  2.95968778e-01  7.64896150e-01\n",
      "  4.34961663e-01  2.53218602e-01  4.82787959e-01  6.14596821e-01\n",
      "  2.88817098e-01  5.28299043e-01  5.02744761e-01  3.70338022e-01\n",
      "  4.67590495e-01  4.12810827e-01  4.57209358e-01  2.17840126e-01\n",
      "  7.32354902e-01  1.81408507e-01  1.90630414e-01 -6.02276097e-03\n",
      "  4.62505004e-01  2.98117466e-01  3.96990425e-01  1.89638119e-01\n",
      "  6.09713968e-01  8.23479283e-01  3.91350206e-01 -5.11166973e-02\n",
      "  6.45006986e-01  2.84228448e-01  4.60089856e-01  2.57878529e-01\n",
      "  4.22845636e-01  3.39132904e-01  2.91634338e-01  3.36750357e-01\n",
      "  1.42232177e-01  8.55535274e-01  1.39781339e-01  5.50350097e-01\n",
      "  4.85706297e-01  4.18023675e-01  1.88129709e-01  5.44666238e-01\n",
      "  3.83871524e-01  5.99672286e-01  4.76277451e-01  2.07847816e-01\n",
      "  4.48255558e-01  4.16126988e-01  1.54633747e-01  2.32085199e-01\n",
      "  4.02328576e-01  4.42038193e-01  2.25232978e-01  1.86103462e-01\n",
      "  2.90600981e-01  3.35385038e-01  3.02496867e-01  3.97464706e-01\n",
      "  4.91594807e-01  5.74987459e-01  4.21448279e-01  6.29319005e-01\n",
      "  5.81523290e-01  1.91922651e-01  7.63293690e-01  2.96632881e-01\n",
      " -1.17437383e-02  3.16470261e-01  2.42884057e-01  3.90296025e-01\n",
      "  5.76625296e-01  6.33140759e-01  3.68940870e-01  1.73121772e-01\n",
      "  1.41139416e-01  2.40393869e-01  4.47411591e-01  2.58548377e-01\n",
      "  6.71106732e-01  4.56459849e-01  1.46439507e-01  1.08507094e-01\n",
      "  5.46457844e-01  4.23642950e-01  4.58725544e-01  4.83437418e-01\n",
      "  2.50122136e-01  3.58072396e-01  6.78832817e-01  4.09902055e-01\n",
      "  3.09709678e-01  3.69221682e-01  1.42276047e-01  1.17970421e-01\n",
      "  2.53164771e-01  5.20892828e-01  5.37773912e-01  7.48622983e-01\n",
      "  4.47560744e-01  7.27516708e-01  9.26292317e-01  3.45707623e-01\n",
      "  4.02682773e-01  2.27394857e-01  4.75837616e-01  1.34903430e-01\n",
      "  4.73012787e-01  3.93786999e-01  5.03572714e-01  1.67239161e-01\n",
      "  1.63462758e-01  4.31637679e-01  7.02776768e-01  1.21596350e-01\n",
      "  6.01091955e-01  3.43893570e-01  6.42785179e-02  2.54718159e-01\n",
      "  7.80033787e-01  3.24893033e-01  9.62184423e-01  8.83986602e-01\n",
      "  7.29118461e-01  4.48561217e-01  3.02282745e-01  3.06372488e-01\n",
      "  4.60958167e-01  8.15998210e-01  2.72657996e-01  5.40020621e-02\n",
      "  1.59369284e-01  3.14630285e-01  3.55846065e-02  4.87800496e-01\n",
      "  4.41344019e-01  1.41621181e-01  2.63402066e-01  6.38625730e-01\n",
      "  2.76864555e-01  1.98861422e-01  3.29424586e-01  9.86969875e-02\n",
      "  4.62582652e-01  8.76991371e-01  4.19393633e-01  4.88628085e-01\n",
      "  1.74878680e-01  5.19538210e-01  2.23608052e-01  1.89008331e-01\n",
      "  3.60059226e-01  3.44433067e-01  1.32539418e-01  2.86711025e-01\n",
      "  4.35463425e-01  3.10323758e-01  4.52647625e-01  2.86522391e-01\n",
      "  3.27988715e-01  4.46706463e-01  4.79808445e-01  1.15578177e-01\n",
      "  1.53258498e-01  5.54910777e-01  6.18512573e-01  3.12467589e-01\n",
      "  9.05123753e-01  8.71513129e-01  1.79405518e-01  1.76278969e-01\n",
      "  4.64023934e-01  5.57103079e-01  2.76101457e-01  8.81279588e-01\n",
      "  3.26309395e-01  2.29606735e-01  4.90459442e-01  3.16235278e-01\n",
      "  4.08940438e-01  7.27378728e-01  5.61117516e-01  2.87643795e-01\n",
      "  5.37448286e-01  7.73190457e-01  1.07089611e-01  2.67319732e-01\n",
      "  7.32167576e-02  8.15327055e-02  5.98396156e-01  7.04343036e-01\n",
      "  5.71077106e-01  8.98022644e-01  2.72327281e-01  5.95382129e-01\n",
      "  5.70001197e-01  6.81254202e-01  5.70645717e-01  4.74534741e-01\n",
      "  2.63248700e-01  3.73813577e-01  2.34372508e-01  6.75711419e-01\n",
      "  4.66351580e-01  4.37025998e-01  1.78962012e-01  4.61811458e-01\n",
      "  6.57528873e-01  4.65013089e-01  9.35634615e-02  4.89992168e-01\n",
      "  1.08905427e-01  5.44892635e-01  6.82942319e-01 -1.50675569e-02\n",
      "  2.94322484e-01  4.90385630e-01  1.83881632e-01  1.24225714e-01\n",
      " -3.77542609e-03  6.09815732e-02  6.83379947e-01  1.75464223e-01\n",
      "  2.51484445e-01  2.69972502e-01  1.44937362e-01  2.90923963e-01\n",
      "  1.44466156e-01  2.52001820e-01  5.83053640e-01  8.17243828e-02\n",
      "  8.06029342e-01  3.19388498e-01  1.58993361e-01  2.46178023e-01\n",
      "  5.65250179e-01  2.47457005e-01  4.66106392e-01  1.61745251e-01\n",
      "  5.91494360e-01  2.25783829e-01  6.38180356e-01  1.81538130e-01\n",
      "  4.94992024e-01  1.36590897e-01  8.05986418e-02  4.65772964e-01\n",
      "  2.18674710e-01  2.77448705e-01  4.68129991e-01  3.42236367e-01\n",
      "  4.72370778e-01  1.94644212e-01  6.04754809e-01  7.01964126e-01\n",
      "  3.43249043e-01  1.31099623e-01  4.47260166e-01  4.75236206e-01\n",
      "  3.14197021e-01  2.60275326e-01  7.44898719e-03  5.72590321e-01\n",
      "  4.45382669e-01  4.20708793e-01  2.46962764e-01  4.80934972e-01\n",
      "  3.42687940e-01  2.66984653e-01  3.68794770e-01  4.18100053e-01\n",
      "  6.43799665e-01  3.03861513e-01  1.05284082e-01  3.83871524e-01\n",
      "  5.57162897e-01  8.67700342e-01  2.79104208e-01  4.91326733e-01\n",
      "  7.63375594e-02  4.25997710e-01 -1.38674287e-01  1.82839979e-02\n",
      "  1.84450092e-01  6.23303143e-01  5.78884913e-01  6.33304734e-01\n",
      "  4.98388862e-01  5.51413324e-01  2.29485923e-01  8.88359640e-01\n",
      "  1.72892314e-01  5.74945160e-01  1.80050536e-01  6.97889571e-02\n",
      "  9.24102925e-02  7.49284885e-01  2.86195336e-01  2.43420055e-01\n",
      "  2.31094697e-01  5.11195100e-01  2.02104068e-01  3.75931789e-01\n",
      "  3.67317861e-01  8.19384737e-01  2.51821460e-01  3.44323698e-01\n",
      "  9.07932339e-01  6.28055022e-01  3.04138993e-01  3.59565833e-01\n",
      "  2.06273182e-01  4.64745966e-01  7.34348919e-01  4.01524928e-01\n",
      "  1.34577425e-01  5.93431652e-01  1.20527999e-01  2.64062272e-01\n",
      "  3.94273698e-01  5.05380462e-01  4.31675673e-01  5.41963096e-01\n",
      "  4.88546420e-02  1.08125394e+00  9.96849066e-02  5.20741735e-01\n",
      "  1.62124012e-01  3.40080500e-01  9.60460652e-01  4.28759331e-01\n",
      "  5.64316117e-01  6.94646320e-01  4.00844785e-01  2.94967110e-01\n",
      "  6.81476415e-01  2.66293749e-02  8.64119073e-01  4.47537489e-01\n",
      "  6.16850990e-01  5.02439926e-01  6.45288356e-01  5.70747449e-01\n",
      "  7.44454422e-02  1.03914594e-01  2.88544807e-01  1.55318895e-01\n",
      "  3.46332682e-01  1.68953286e-01  1.80649485e-01  3.75281018e-01\n",
      "  4.27931650e-01  2.41348369e-01  7.45693272e-01  3.41910460e-01\n",
      "  6.81932671e-01  1.97947371e-01  5.64269249e-01  6.02824535e-01\n",
      "  3.17316556e-01  6.44582971e-02  1.81077862e-01  3.93978370e-01\n",
      "  5.85328370e-01  3.60481498e-01  6.74296661e-01  2.57780046e-01\n",
      "  4.95123075e-01  4.85441713e-01  5.29664420e-01  1.34319735e-01\n",
      "  2.80388840e-01  7.74280310e-01  1.61818143e-01  3.17657265e-01\n",
      "  1.96210173e-01  9.97080240e-02  3.38986436e-01  2.61734702e-01\n",
      "  2.68961325e-01  2.38550738e-01  1.82628775e-01  5.52825721e-01\n",
      "  2.76817475e-01  3.43056494e-02  5.37819040e-01  5.90750229e-01\n",
      "  1.98924140e-01  1.46016489e-01  3.91701908e-01  3.20381563e-01\n",
      "  2.72329478e-01  3.10973686e-01  3.36455249e-01  4.06548106e-01\n",
      "  3.96739684e-01  4.78860540e-01  4.34271350e-01  3.38875402e-01\n",
      "  3.87542025e-01  1.14056761e-01  1.08122893e-01  4.01353109e-01\n",
      "  4.44248071e-01  6.83389382e-01  3.74784781e-01  1.07283804e-01\n",
      "  1.21088992e-01  4.26998577e-01  4.01727293e-01  5.91821824e-01\n",
      "  2.02013130e-01  4.49370827e-01 -6.03327420e-02  9.99902582e-02\n",
      "  5.45378672e-01  7.82079599e-01  9.19291814e-02  5.93823686e-01\n",
      "  4.33510245e-01  5.63249602e-01  1.84052785e-01  4.02018335e-01\n",
      "  2.94765569e-01  5.62243195e-01  4.74920050e-01  5.64341932e-01\n",
      "  5.62869953e-01  7.05124254e-01  2.80196231e-01  5.51101859e-01\n",
      "  5.85885328e-01  6.56221604e-01  5.36511439e-01  2.71937716e-01\n",
      "  4.96223172e-01  2.52438448e-01  1.94990717e-02  3.50764686e-01\n",
      "  8.73405919e-01  5.30369277e-01  8.57558872e-02  1.68492880e-01\n",
      "  6.79609473e-01  2.38812902e-01  8.40788457e-01  9.68259485e-01\n",
      "  5.57053268e-01  2.63116030e-01 -1.11401035e-01  3.48808549e-01\n",
      "  4.20055507e-02  2.11501396e-01  3.15653977e-02  7.31363657e-02\n",
      "  3.92941809e-01  4.40917817e-01  3.95500197e-01  2.15339272e-01\n",
      "  2.10649103e-01  3.68115327e-01  8.27284857e-01  2.52705714e-01\n",
      "  2.17840126e-01  4.94916038e-01  4.12775696e-01  3.91630524e-01\n",
      "  8.10675107e-01  3.74753285e-01  5.75589827e-01  4.73086338e-01\n",
      "  1.09778789e-01  8.51566440e-01  1.91208910e-01  3.30884531e-01\n",
      "  3.91942964e-01  5.28541270e-01  3.05050363e-01  3.13211051e-01\n",
      "  3.95654058e-01  4.44068469e-01  2.62721222e-01  4.83170545e-01\n",
      "  9.08912688e-01  5.86394161e-01  4.08597209e-01  1.53778088e-01\n",
      " -2.32895509e-02  3.37366583e-01  4.46657688e-01  3.74713412e-01\n",
      "  3.55460567e-01  3.62088476e-01  3.08071010e-01  6.45901115e-01\n",
      "  1.73186515e-01  5.26757885e-01  2.99883780e-01  7.03946882e-01\n",
      "  3.01615970e-01  5.28760765e-01  2.42214519e-01  4.78400615e-01\n",
      "  1.66853732e-01  5.72988930e-01  5.14183838e-01  2.79230189e-01\n",
      "  6.55754116e-01  5.05192387e-01  5.78648741e-01  1.70127336e-01\n",
      "  1.63226535e-01  4.00331086e-01  3.31590349e-01  7.37765399e-01\n",
      "  6.85257933e-01  8.77910720e-02  5.48221406e-01  3.49815371e-01\n",
      "  2.58720876e-01  3.70297410e-01  1.28650409e-01  8.06965285e-01\n",
      "  8.32955936e-01  5.38278669e-01  3.39165539e-01  2.91123156e-01\n",
      "  6.19407150e-02  4.01167323e-01  4.99255458e-01  5.12566384e-01\n",
      "  7.01296977e-01  4.91266533e-01  6.21377781e-01  2.44819467e-01\n",
      "  1.95519960e-01  3.83029099e-01  6.46272298e-01  3.40431368e-02\n",
      "  5.83848169e-01  1.61745251e-01  5.19747266e-01  1.72651757e-01\n",
      "  3.52257253e-01  7.34097511e-03  2.38190505e-01  5.97099521e-02\n",
      "  1.88180535e-02  7.30623994e-01  1.73474331e-02  3.23302903e-01\n",
      "  4.94423986e-01  3.76825746e-01  2.92636740e-01  2.21087181e-01\n",
      "  3.35361421e-01  7.09014727e-01  7.82188115e-01  4.04162126e-01\n",
      "  4.32473227e-01  7.38257451e-01  6.32433053e-01  4.91704282e-01\n",
      "  3.69706341e-01  9.01103937e-01  5.13762058e-01  3.26004502e-01\n",
      "  5.06106022e-01  3.34218329e-01  4.30334514e-01  4.76157351e-01\n",
      "  3.58515256e-01  2.48204849e-01  1.27634601e-01  7.99383171e-01\n",
      "  6.97741623e-01  5.36592529e-01  3.33569594e-01  9.13352784e-01\n",
      "  1.66157107e-01  1.80037432e-01  2.83090075e-01  7.40886471e-01\n",
      "  4.24759043e-01  7.50368040e-01  2.68907188e-01  4.58714916e-01\n",
      "  1.45400024e-01  5.68902995e-01  7.05643122e-01  1.93675845e-01\n",
      "  3.87910383e-01  1.58330148e-01  6.42770245e-01  5.58106279e-01\n",
      "  4.93346119e-01  5.19168309e-01  5.66016974e-01  1.06317687e+00\n",
      "  3.49979537e-01  3.18007919e-01  2.04614856e-01  1.74202571e-01\n",
      "  5.96212687e-01  3.92352852e-01  7.18506273e-01  5.51149693e-01\n",
      "  4.08185298e-02  2.81863742e-01  6.99231620e-01  4.01344172e-01\n",
      "  5.59904898e-01  1.51732317e-01  2.77081510e-01  6.34530111e-01\n",
      "  5.75286439e-01  4.65199203e-01  6.69271001e-01  7.95012336e-01\n",
      "  6.47152523e-01  3.04936818e-01  7.34714782e-01  4.31380300e-01\n",
      "  1.42029252e-01  3.30391736e-01  1.57325493e-01  5.62702590e-01\n",
      "  2.82778263e-01  2.95945012e-01  5.02499287e-01  2.06816671e-01\n",
      "  2.17271927e-01  4.58371459e-01  8.04215848e-01  1.11913999e-01\n",
      "  4.59309765e-01  8.00576663e-01  2.74063153e-01  1.22013441e-01\n",
      "  1.44857867e-01  6.08959531e-01  8.31059016e-01  4.91751858e-01\n",
      "  4.92542912e-01  7.64859532e-02  5.79447351e-01  6.56966507e-01\n",
      "  3.39301957e-01  3.02761215e-01  1.38724691e-01  2.53334517e-01\n",
      "  4.56676172e-01  2.23204036e-01  4.32586278e-01  7.84423804e-01\n",
      "  4.55729284e-01  1.51486058e-01  5.88913210e-01  3.75414389e-01\n",
      "  5.64180152e-01  1.98965443e-01  6.70134040e-01  1.60982703e-01\n",
      "  2.13429872e-01  5.54542111e-01  2.75370119e-01  2.44830937e-01\n",
      "  4.07840151e-01  8.97422876e-02  5.05398723e-01  1.00256039e-01\n",
      "  6.22728671e-01  3.54689513e-02  5.03332968e-01  1.83227222e-01\n",
      "  2.15368327e-01  7.81159909e-01  1.42633494e-01  3.57996741e-01\n",
      "  5.02777818e-01  6.21979927e-01  6.50090779e-01  5.02839792e-01\n",
      "  1.84267203e-01  3.32780171e-01  4.68916446e-02  7.78420590e-01\n",
      "  1.98826571e-01  7.14137876e-01  5.51272035e-01  3.23775766e-01\n",
      "  2.25153023e-01  1.32546554e-01  3.92659181e-01  5.84599407e-01\n",
      "  6.08852081e-02  4.24438305e-01  3.24243771e-01  5.30956001e-01\n",
      "  7.29496720e-01  3.97332376e-01  1.48959343e-01  2.34405794e-01\n",
      " -5.84053588e-02  4.98959405e-01  9.00114871e-01  2.08029244e-01\n",
      "  7.00380491e-01  7.30708458e-01  2.24512862e-02  8.06458864e-01\n",
      "  4.20692581e-01  5.14404862e-01  6.04754809e-01  4.78330552e-01\n",
      "  4.27276885e-01  1.91008090e-01  7.09091086e-01  1.81997857e-01\n",
      "  8.08812370e-01  3.84312187e-01  7.85074837e-01  1.00209293e-01\n",
      "  2.32784335e-01  2.63432313e-01  2.43641453e-01  9.12094181e-02\n",
      "  4.16129318e-01 -8.00035141e-05  1.76049476e-01  7.54031227e-01\n",
      "  3.40802434e-01  2.54954020e-01  6.09671040e-02  1.44041070e-01\n",
      "  5.60137002e-01  1.97992276e-01  4.47695830e-01  6.37838444e-01\n",
      "  5.46565203e-01 -1.35776235e-02  8.55443356e-02  3.89584873e-01\n",
      "  1.39092318e-01  6.69056650e-01  3.62764624e-01  5.33618465e-01\n",
      "  3.97448076e-01  5.10683002e-01  2.34829287e-01  4.67863362e-02\n",
      "  5.34539505e-02  1.20446421e-01  3.29960165e-01  6.38578437e-01\n",
      "  3.97558921e-01  2.23793986e-01  4.27948328e-01  3.63761228e-01\n",
      "  6.47012565e-01  1.06297068e-01  6.87273391e-01  5.63916537e-01]\n"
     ]
    }
   ],
   "source": [
    "#our best model was SVR.\n",
    "svr = SVR(gamma=0.001, C=10)\n",
    "svr.fit(nX_train, y_train)\n",
    "preds = svr.predict(nX_ivs)\n",
    "print('y_ivs:',preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e83e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
